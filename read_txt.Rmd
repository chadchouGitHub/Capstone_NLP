---
title: "read_txt"
author: "Chia-Ching Chou"
date: "March 16, 2015"
output:
  html_document:
    keep_md: yes
---
Here is reading the txt file into r.
I use readLines().
It took several mins to read one txt file.

Note: Something went wrong during knit HTML, but rm file still OK.
There is no problem when I just run this three readLines() in different r script file.
```{r}
nLpBlogs <- readLines("final/en_US/en_US.blogs.txt")
nLpNews <- readLines("final/en_US/en_US.news.txt")
nLpTwitter <- readLines("final/en_US/en_US.twitter.txt")
cBlog <- paste(nLpBlogs, collapse = " ") ## I only take first 10 elements. whole txt file is too big.
cBlog <- as.String(cBlog)
word_ann <- Maxent_Word_Token_Annotator()
sent_ann <- Maxent_Sent_Token_Annotator()
cBlog_annotations <- annotate(cBlog, list(sent_ann, word_ann))

head(cBlog_annotations)

cBlog_doc <- AnnotatedPlainTextDocument(cBlog, cBlog_annotations)


lenOfNews<- nchar(nLpNews)

lenOfBlog<- nchar(nLpBlogs)
summary(lenOfBlog)

head(sents(cBlog_doc)[1:2])
head(words(cBlog_doc))
tail(nLpBlogs)

```
## Here are error message!
processing file: read_txt.Rmd

Quitting from lines 15-20 (read_txt.Rmd) 
Error in file(con, "r") : cannot open the connection
Calls: <Anonymous> ... withCallingHandlers -> withVisible -> eval -> eval -> readLines -> file
Execution halted

# If you know what is this, please tell me how to fix.


Note: In the task 1, Data acquisition and cleaning, suggests use connection function, file(), url(), gzfile()...
It will only read part of data from file or url ...

```{r}
con <- file("final/en_US/en_US.blogs.txt","r") ## This is a connection to one of the file.

lineOne<- readLines(con, 1)
lineFive <- readLines(con, 5)

## In this way, I can just read part of txt w/o take to much time to hold on computer.

close(con) ## What happen if I don't close con?
## One connection close, you need to open it again.
## Below scan() does not work for me.
scanLineOne <- scan("final/en_US/en_US.blogs.txt",skip=1, nlines = 1:3) ##????? still don't know.
scanLineFive <- scan(con)
```

scan() function practice.
```{r}
cat("TITLE extra line", "2 3 5 7", "11 13 17", file = "ex.data", sep = "\n") ## Make a ex.data txt file. 
pp <- scan("ex.data", skip = 1, quiet = TRUE)

pP1 <- scan("ex.data", skip = 1)
pP2 <- scan("ex.data", skip = 1, nlines = 1) # only 1 line after the skipped one
pP3 <- scan("ex.data", what = list("","","")) # flush is False -> read "7"
pP4 <- scan("ex.data", what = list("","",""), flush = TRUE)
unlink("ex.data") # tidy up


```

```{r}

loveBlog<- grep("love",nLpBlogs, value=T)
hateBlog<- grep("hate",nLpBlogs, value=T)

loveTwitter<- grep("love",nLpTwitter, value=T)
hateTwitter<- grep("hate",nLpTwitter, value=T)
length(loveTwitter)
length(hateTwitter)

longStatTwitter<- grep("A computer once beat me at chess, but it was no match for me at kickboxing",nLpTwitter, value=T)

getblog<- grep("must be asleep",blogs, value=T)
gettwitter<- grep("must be asleep",twitter, value=T)
getnews<- grep("must be asleep",news, value=T)



```


